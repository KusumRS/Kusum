{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_table('C:/Users/Adithya Arunganesh/Desktop/Projects/DNA Sequencing/human_data.txt')\n",
    "dog = pd.read_table('C:/Users/Adithya Arunganesh/Desktop/Projects/DNA Sequencing/dog_data.txt')\n",
    "chimp = pd.read_table('C:/Users/Adithya Arunganesh/Desktop/Projects/DNA Sequencing/chimp_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGCCCCAACTAAATACCGCCGTATGACCCACCATAATTACCCCCA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGAACGAAAATCTATTCGCTTCATTCGCTGCCCCCACAATCCTAG...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATGGCCTCGCGCTGGTGGCGGTGGCGACGCGGCTGCTCCTGGAGGC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGGCCTCGCGCTGGTGGCGGTGGCGACGCGGCTGCTCCTGGAGGC...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATGGGCAGCGCCAGCCCGGGTCTGAGCAGCGTGTCCCCCAGCCACC...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  class\n",
       "0  ATGCCCCAACTAAATACCGCCGTATGACCCACCATAATTACCCCCA...      4\n",
       "1  ATGAACGAAAATCTATTCGCTTCATTCGCTGCCCCCACAATCCTAG...      4\n",
       "2  ATGGCCTCGCGCTGGTGGCGGTGGCGACGCGGCTGCTCCTGGAGGC...      4\n",
       "3  ATGGCCTCGCGCTGGTGGCGGTGGCGACGCGGCTGCTCCTGGAGGC...      4\n",
       "4  ATGGGCAGCGCCAGCCCGGGTCTGAGCAGCGTGTCCCCCAGCCACC...      6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.head()\n",
    "dog.head()\n",
    "chimp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5, 2, 6, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human['class'].unique()\n",
    "#There are 7 classes of gene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating DNA sequence as a \"language\", otherwise known as k-mer counting\n",
    "A challenge that remains is that none of these above methods results in vectors of uniform length, and that is a requirement for feeding data to a classification or regression algorithm. So with the above methods you have to resort to things like truncating sequences or padding with \"n\" or \"0\" to get vectors of uniform length.\n",
    "\n",
    "DNA and protein sequences can be viewed metaphorically as the language of life. The language encodes instructions as well as function for the molecules that are found in all life forms. The sequence language analogy continues with the genome as the book, subsequences (genes and gene families) are sentences and chapters, k-mers and peptides (motifs) are words, and nucleotide bases and amino acids are the alphabet. Since the analogy seems so apt, it stands to reason that the amazing work done in the natural language processing field should also apply to the natural language of DNA and protein sequences.\n",
    "\n",
    "The method I use here is simple and easy. I first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if I use \"words\" of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
    "\n",
    "Here I am using hexamer “words” but that is arbitrary and word length can be tuned to suit the particular situation. The word length and amount of overlap need to be determined empirically for any given application.\n",
    "\n",
    "In genomics, we refer to these types of manipulations as \"k-mer counting\", or counting the occurances of each possible k-mer sequence. There are specialized tools for this, but the Python natural language processing tools make it supe easy.\n",
    "\n",
    "Here is a function that can be used to convert any sequence (string) to overlapping k-mer words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to collect all possible overlapping k-mers of a specified length from any sequence string. We will basically apply the k-mers to the complete sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert sequence string into k-mer words, default size is 6 known as hexamer\n",
    "\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We broke the sequence in length of 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the training set sequence into short overlapping k-mers of length 6 and we apply the getKmer function to other species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "human['words']=human.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "human=human.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp['words']=chimp.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "chimp=chimp.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog['words']=dog.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "dog=dog.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              words\n",
       "0      4  [atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...\n",
       "1      4  [atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...\n",
       "2      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "3      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "4      3  [atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since we are going to use scikit-learn natural language processing tools to do the k-mer counting, we need to now convert the lists of k-mers for each gene into string sentences of words that the count vectorizer can use. We can also make a y variable to hold the class labels. Let's do that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text=list(human['words'])\n",
    "\n",
    "for item in range(len(human_text)):\n",
    "    human_text[item]=' '.join(human_text[item])\n",
    "    \n",
    "    \n",
    "y_human=human.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 3, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply same process for Chimp and Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_text=list(chimp['words'])\n",
    "\n",
    "for item in range(len(chimp_text)):\n",
    "    chimp_text[item]=' '.join(chimp_text[item])\n",
    "    \n",
    "    \n",
    "y_chimp=chimp.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_text=list(dog['words'])\n",
    "\n",
    "for item in range(len(dog_text)):\n",
    "    dog_text[item]=' '.join(dog_text[item])\n",
    "    \n",
    "    \n",
    "y_dog=dog.iloc[:, 0].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Bag of Words using CountVectorizer using NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Words model using CountVectorizer()\n",
    "# This is equivalent to k-mer counting\n",
    "# The n-gram size of 4 was previously determined by testing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(4,4))\n",
    "\n",
    "X_human = cv.fit_transform(human_text)\n",
    "X_chimp = cv.transform(chimp_text)\n",
    "X_dog = cv.transform(dog_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 232414)\n",
      "(1682, 232414)\n",
      "(820, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(X_human.shape) #for human we have 4380 genes converted into uniform length feature vectors of 4-gram k-mer(length 6) counts.\n",
    "print(X_chimp.shape)\n",
    "print(X_dog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a look at class balance we can see we have relatively balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26fbed618c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "human['class'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X_human, y_human, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 232414)\n",
      "(876, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi=MultinomialNB(alpha=0.1)\n",
    "multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=multi.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      "Predicted   0    1   2    3    4   5    6\n",
      "Actual                                   \n",
      "0          99    0   0    0    1   0    2\n",
      "1           0  104   0    0    0   0    2\n",
      "2           0    0  78    0    0   0    0\n",
      "3           0    0   0  124    0   0    1\n",
      "4           1    0   0    0  143   0    5\n",
      "5           0    0   0    0    0  51    0\n",
      "6           1    0   0    1    0   0  263\n",
      "accuracy = 0.984 \n",
      "precision = 0.984 \n",
      "recall = 0.984 \n",
      "f1 = 0.984\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix\\n\")\n",
    "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "\n",
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
